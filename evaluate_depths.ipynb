{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/spektor/miniconda3/envs/baskin/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "WARNING:root:The OGB package is out of date. Your version is 1.3.4, while the latest version is 1.3.5.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "directory_path = os.path.abspath(os.path.join('..'))\n",
    "if directory_path not in sys.path:\n",
    "    sys.path.append(directory_path)\n",
    "  \n",
    "from trainer import Trainer\n",
    "from dataset import get_ogb_data\n",
    "from torch_geometric import seed_everything\n",
    "from torch_geometric.nn import SAGEConv, GCNConv, GATConv\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from ogb.nodeproppred import Evaluator\n",
    "from gnn_model import GNN\n",
    "from predict import evaluate_test\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEEP_DEPTH = 16\n",
    "SHALLOW_DEPTH = 2 \n",
    "depths_list = [DEEP_DEPTH, SHALLOW_DEPTH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in the graph: 169343\n",
      "Number of edges in the graph: 1166243\n",
      "Number of training nodes: 90941\n",
      "Number of validation nodes: 29799\n",
      "Number of test nodes: 48603\n",
      "Node feature matrix with shape: torch.Size([169343, 128])\n",
      "Graph connectivity in COO format with shape: torch.Size([2, 1166243])\n",
      "Target to train against : torch.Size([169343, 1])\n",
      "Node feature length 128\n",
      "number of target categories: 40\n"
     ]
    }
   ],
   "source": [
    "d_name = 'arxiv'\n",
    "data, split_idx, num_classes = get_ogb_data('arxiv')\n",
    "evaluator = Evaluator(name=f'ogbn-{d_name}')\n",
    "\n",
    "def load_model(model_type, depth, data, num_classes):\n",
    "    \n",
    "    max_depth = 2 if depth == 'shallow' else 16\n",
    "    \n",
    "    if model_type=='SAGE':\n",
    "        model = GNN(SAGEConv, data.x.shape[1], data.x.shape[1], num_classes, n_layers=max_depth)\n",
    "    elif model_type=='GCN':\n",
    "        model = GNN(GCNConv, data.x.shape[1], data.x.shape[1], num_classes, n_layers=max_depth)\n",
    "    elif model_type=='GAT':\n",
    "        model = GNN(GATConv, data.x.shape[1], data.x.shape[1], num_classes, n_layers=max_depth)\n",
    "\n",
    "    model_dir = f'{depth}_{model_type}'\n",
    "    best_pth_fn = os.path.join(model_dir,'model_best.pth')\n",
    "    if os.path.exists(best_pth_fn):\n",
    "        checkpoint = torch.load(best_pth_fn)\n",
    "        model.load_state_dict(checkpoint['network_state_dict'], strict=False)\n",
    "        print(f'{depth}_{model_type} loaded')\n",
    "    return model\n",
    "\n",
    "def load_test_loader(data, test_idx):\n",
    "    test_loader = NeighborLoader(data, input_nodes=test_idx, num_neighbors=[-1],\n",
    "                                    batch_size=128, shuffle=True)\n",
    "    print('Test loader loaded')\n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_types = ['GAT', 'GCN']\n",
    "depth_types = ['both']\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "test_idx = split_idx['test']\n",
    "num_permutations = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shallow_GAT loaded\n",
      "Test loader loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [22:06<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deep_GAT loaded\n",
      "Test loader loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [58:19<00:00,  3.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "both_GAT loaded\n",
      "Test loader loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [58:26<00:00,  3.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shallow_GCN loaded\n",
      "Test loader loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [16:42<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deep_GCN loaded\n",
      "Test loader loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [32:27<00:00,  1.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "both_GCN loaded\n",
      "Test loader loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [32:26<00:00,  1.95s/it]\n"
     ]
    }
   ],
   "source": [
    "for model_type in model_types:\n",
    "    for depth_type in depth_types:\n",
    "        model = load_model(model_type, depth_type, data, num_classes)\n",
    "        model.to(device)\n",
    "        test_loader = load_test_loader(data, test_idx)\n",
    "\n",
    "        nods_results_depths_dict = {}\n",
    "        ids_col = {'id': test_idx}\n",
    "        id_depths_df = pd.DataFrame(data=ids_col)\n",
    "        id_results_df = pd.DataFrame(data=ids_col)\n",
    "\n",
    "        for perm in tqdm(range(num_permutations)):\n",
    "            test_acc, inference_depths, ids, correctness = evaluate_test(model, test_loader, evaluator, data, depths_list, device)\n",
    "            \n",
    "            temp_df = pd.DataFrame(data={'id': ids, f'depth_{perm}': inference_depths})\n",
    "            temp_df.sort_values(by=['id'], inplace=True)\n",
    "            id_depths_df = id_depths_df.merge(temp_df, on='id')\n",
    "            \n",
    "            temp_df = pd.DataFrame(data={'id': ids, f'correctness_{perm}': correctness})\n",
    "            temp_df.sort_values(by=['id'], inplace=True)\n",
    "            id_results_df = id_results_df.merge(temp_df, on = 'id')\n",
    "            \n",
    "        sorted_ids = ids_col['id'].tolist()\n",
    "        all_correctnesses = list(id_results_df.drop(['id'], axis=1).to_numpy().flatten())\n",
    "        all_depths = list(id_depths_df.drop(['id'], axis=1).to_numpy().flatten())\n",
    "        all_sorted_ids = list(np.repeat(sorted_ids, num_permutations))\n",
    "        all_results_df = pd.DataFrame(data={'id': all_sorted_ids, 'correctness': all_correctnesses, 'depth': all_depths})\n",
    "        \n",
    "        id_depths_df.to_csv(f'id_depths_{depth_type}_{model_type}.csv', index=False)\n",
    "        id_results_df.to_csv(f'id_results_{depth_type}_{model_type}.csv', index=False)\n",
    "        all_results_df.to_csv(f'all_results_{depth_type}_{model_type}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAT both\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48603/48603 [59:27<00:00, 13.63it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN both\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48603/48603 [56:48<00:00, 14.26it/s] \n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import permutation_test\n",
    "\n",
    "def statistic(x, y, axis):\n",
    "    return np.mean(x, axis=axis) - np.mean(y, axis=axis)\n",
    "\n",
    "results_folder = 'results'\n",
    "for model_type in model_types:\n",
    "    for depth_type in depth_types:\n",
    "        print(f'{model_type} {depth_type}')\n",
    "        all_results_df = pd.read_csv(os.path.join(results_folder, f'all_results_{depth_type}_{model_type}.csv'))\n",
    "        ids_to_pvalue = {}\n",
    "        for id in tqdm(np.array(test_idx)):\n",
    "            id_df = all_results_df[all_results_df['id'] == id].copy()\n",
    "            x = np.array(id_df[id_df['depth'] == 2]['correctness'])\n",
    "            y = np.array(id_df[id_df['depth'] == 16]['correctness'])\n",
    "            try:\n",
    "                res_less = permutation_test((x, y), statistic, vectorized=True,\n",
    "                                        n_resamples=1000, alternative='less')\n",
    "            \n",
    "                res_greater = permutation_test((x, y), statistic, vectorized=True,\n",
    "                                    n_resamples=1000, alternative='greater')\n",
    "            except:\n",
    "                continue\n",
    "            ids_to_pvalue[id] = (res_less.pvalue, res_greater.pvalue)\n",
    "        # create dataframe with pvalues\n",
    "        df = pd.DataFrame.from_dict(ids_to_pvalue, orient='index', columns=['pvalue_less', 'pvalue_greater'])\n",
    "        df.index.name = 'ids'                           \n",
    "        df.to_csv(f'results/ids_to_pvalue_{model_type}_{depth_type}.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('baskin': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e591c4f2b87a250375ca884dffd1dc17c4ce3268c519c9ae9b05ed9c4bef7107"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
